{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_Training_NB.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qmqnrUVu7qe"
      },
      "source": [
        "On order to be able to train with GPU:\n",
        "Edit->Notebook Settings->Hardware Accelerator->Select GPU\n",
        "\n",
        "Execute one cell after the other.\n",
        "\n",
        "The Dataset has to be uploaded as a .zip File to your Google drive, containing all images and the csv file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z409MvsgRhEx"
      },
      "source": [
        "The first Cell contains the Model Definition\n",
        "\n",
        "Paste your Model here:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPR3Vl7UQrw5"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DenseLayer(nn.Module):        #also called bottleneck Layer (Used for DenseNet-BC Variants)\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DenseLayer, self).__init__()\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels * 4, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
        "        #1x1 kernel hat ko + k*(l-1) input channels, und erzeugt 4*32 outputs, welche zu 3x3 kernel gehen. Dies dient vor allem der Parameterreduzierung\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels * 4)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels * 4, out_channels, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out1 = self.conv1(self.relu1(self.bn1(x)))  #input wird zunächst von 1x1 kernel gefiltert\n",
        "        out = self.conv2(self.relu2(self.bn2(out1))) #anschließend wird 3x3 kernel genutzt, welcher 32 output channels erzeugt\n",
        "        return torch.cat([x, out], 1)\n",
        "\n",
        "class TransitionBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(TransitionBlock, self).__init__()\n",
        "                \n",
        "        self.bn = nn.BatchNorm2d(in_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
        "        self.pool = nn.AvgPool2d(kernel_size=2,stride=2,padding=0)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.pool(self.conv(self.relu(self.bn(x)))) \n",
        "        return out\n",
        "    \n",
        "class DenseBlock(nn.Module):\n",
        "    def __init__(self, layer_size, in_channels, growth_rate):   #growth_rate (k in paper) is equal to amount of output channels for each layer\n",
        "        super(DenseBlock, self).__init__()\n",
        "        \n",
        "        self.block = []\n",
        "        for i in range(layer_size):\n",
        "            self.block.append(DenseLayer(in_channels+i*growth_rate,growth_rate))      #input = k0 + (l-1)*k, k0 = in_channels, l-1 = i (l = amount of layers before current layer)\n",
        "            \n",
        "        self.block = nn.Sequential(*self.block)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.block(x)\n",
        "        return out\n",
        "    \n",
        "class DenseNet(nn.Module):\n",
        "    def __init__(self, in_channels=2, layer_size=[6,6,7,8], growth_rate=12, additional_neurons = 8):  #in_channels describes picture channels (3 for rgb)  #layer_size must be list of 4 Elements\n",
        "        super(DenseNet, self).__init__()\n",
        "        \n",
        "        self.out_channels = 2 * growth_rate #for k = 32 ->  64\n",
        "        self.in_channels = 0    #used later\n",
        "        \n",
        "        #First Convolution & Pooling\n",
        "        self.conv1 = nn.Conv2d(in_channels, self.out_channels, kernel_size=7, stride = 2, padding = 3, bias = False)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(self.out_channels)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "        \n",
        "        #FirstDenseBlock\n",
        "        self.in_channels = self.out_channels #2*growth_rate -> 64\n",
        "        self.out_channels = growth_rate\n",
        "        self.DenseBlock1 = DenseBlock(layer_size[0], self.in_channels, growth_rate) #6 Denselayer\n",
        "        \n",
        "        #First Transition Layer\n",
        "        self.in_channels = self.in_channels + growth_rate * layer_size[0] #256\n",
        "        self.out_channels = int(self.in_channels/2) #128\n",
        "        self.TransitionLayer1 = TransitionBlock(self.in_channels, self.out_channels)\n",
        "        \n",
        "        #Second DenseBlock\n",
        "        self.in_channels = self.out_channels    #128 in channels\n",
        "        self.out_channels = growth_rate\n",
        "        self.DenseBlock2 = DenseBlock(layer_size[1], self.in_channels, growth_rate) #12 Denselayer         \n",
        "        \n",
        "        #Second Transition Layer\n",
        "        self.in_channels = self.in_channels + growth_rate * layer_size[1] #512\n",
        "        self.out_channels = int(self.in_channels/2) #256\n",
        "        self.TransitionLayer2 = TransitionBlock(self.in_channels, self.out_channels)\n",
        "        \n",
        "        #Third DenseBlock\n",
        "        self.in_channels = self.out_channels    #256 in channels\n",
        "        self.out_channels = growth_rate\n",
        "        self.DenseBlock3 = DenseBlock(layer_size[2], self.in_channels, growth_rate) #24 Denselayer  \n",
        "        \n",
        "        #Third Transition Layer\n",
        "        self.in_channels = self.in_channels + growth_rate * layer_size[2] #1024\n",
        "        self.out_channels = int(self.in_channels/2) #512\n",
        "        self.TransitionLayer3 = TransitionBlock(self.in_channels, self.out_channels)\n",
        "        \n",
        "        #Fourth DenseBlock\n",
        "        self.in_channels = self.out_channels    #512 in channels\n",
        "        self.out_channels = growth_rate\n",
        "        self.DenseBlock4 = DenseBlock(layer_size[3], self.in_channels, growth_rate) #16 Denselayer\n",
        "        \n",
        "        #Global Average Pooling -> Compresses all channels of size 3x2 to size 1x1 (for input neurons)\n",
        "        self.global_avg_pool = nn.AvgPool2d(kernel_size=(2,3),stride=4,padding=0)       #kernel size of 3x2 depends on input size of image!!!!\n",
        "        \n",
        "        self.in_channels = self.in_channels + growth_rate*layer_size[3] #1024\n",
        "        self.batchnorm2 = nn.BatchNorm2d(self.in_channels)\n",
        "        \n",
        "        #fully connected layer\n",
        "        self.in_channels = self.in_channels+additional_neurons\n",
        "        self.fully_connected = nn.Linear(self.in_channels, 4)     #in_features = 1024 + additional neurons used as input, output = 4 (steering_left, steering_right, acceleration, brake)\n",
        "        \n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "        #initialization of all weights\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "                \n",
        "    def forward(self, x, a):   #x = Tensor of Image (96*85*in_channels -> specified in constructor of DenseNet), a = List of other Inputs\n",
        "        x = self.maxpool(self.relu1(self.batchnorm1(self.conv1(x))))\n",
        "        x = self.TransitionLayer1(self.DenseBlock1(x))       \n",
        "        x = self.TransitionLayer2(self.DenseBlock2(x))\n",
        "        x = self.TransitionLayer3(self.DenseBlock3(x))\n",
        "        x = self.DenseBlock4(x)\n",
        "        x = self.global_avg_pool(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        if not torch.cuda.is_available():\n",
        "          a = torch.Tensor(a)\n",
        "        a = torch.squeeze(a, 0)\n",
        "        x = torch.squeeze(x, 0)\n",
        "        if(len(a.size()) > 1):  #checks if a is passed as batch or single value\n",
        "            x = torch.cat((x,a),1)      #concatenate tensor x and a alsong dimension 1, since dimension zero is reserved by batch\n",
        "        else:\n",
        "            x = torch.cat((x,a),0)      #concatenate tensor x and a along dimension 0 (in evaluation mode)\n",
        "        output = self.fully_connected(x)\n",
        "        output = self.sigmoid(output)\n",
        "        return output\n",
        "    \n",
        "\n",
        "def count_parameters(model):        #Function to count learnable parameters of model\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4FihplnRsFr"
      },
      "source": [
        "The second cell mounts google Drive to Colab.\n",
        "You don't have to change anything in the code, just execute and follow the steps described."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_CEoHdZgkSD"
      },
      "source": [
        "#make sure to execute this code snipped before you start training\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "#you will be asked to enter the authorization code of your google account - only valid for one session\n",
        "#Go to this URL in a browser in order to obtain your key: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fexperimentsandconfigs%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\"\"\"\n",
        "gdrive can now be accessed under: \n",
        "content/gdrive/MyDrive/\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkpcGccIR5iA"
      },
      "source": [
        "The third cell unzips the training data file stored on your google drive.\n",
        "You have to provide the path of the zip file in the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwkhq1zGGlFH"
      },
      "source": [
        "#google drive connection - Paste the path where you stored the zip on your drive here\n",
        "#go to files (folder on the left side) -> gdrive ->... and navigate to the training data folder (zip file)\n",
        "#copy the path of the folder and the csv file (by clicking on the three dots) and paste them here\n",
        "\n",
        "!unzip \"/content/gdrive/MyDrive/training_v2.zip\"\n",
        "\n",
        "#files will now be unzipped and stored locally on google colab -> increases speed drastically"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWbayORQTdCU"
      },
      "source": [
        "In the fourth cell the DataLoader is prepared. Therefore you have to provide the csv path and the root directory in line 14&15 (on google colab). Copy the path by clicking on the three dots.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsLy8GAje6al",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "21455b20-17c7-41d9-a277-e63b18d55fb8"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "import pandas as pd\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "print(\"all libraries are imported successfully...\")\n",
        "\n",
        "csv_path = \"/content/training_v2/labels.csv\"      #provide csv path (same name as zipped folder, but now locally, not on drive)\n",
        "root_dir = \"/content/training_v2\"                 #provide root dir (same name as zipped folder, but now locally, not on drive)\n",
        "\n",
        "# create a dataset class\n",
        "# torch.utils.data.Dataset is an abstract clas representing a dataset\n",
        "class SteeringCommands(Dataset): \n",
        "    \"\"\" Steering Commands dataset \"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, root_dir, transform=None): \n",
        "        \"\"\"\n",
        "            Args:\n",
        "                csv_file (string): Path to the csv file with annotations.\n",
        "                root_dir (string): Directory with all the images.\n",
        "                transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.label_file = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transforms = transform\n",
        "\n",
        "    def __len__(self): \n",
        "        return len(self.label_file)\n",
        "\n",
        "    def __getitem__(self, idx): \n",
        "        if torch.is_tensor(idx): \n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = os.path.join(self.root_dir, self.label_file.iloc[idx,11])\n",
        "        image = io.imread(img_name)\n",
        "        image = image[:,:,0:2]      #remove blue color channel from image\n",
        "        commands = self.label_file.iloc[idx, 8:11]\n",
        "        commands = np.asarray(commands)\n",
        "        if commands[0] == 1.0:           #append 0/1 depending on turning key value -> defines input for right key\n",
        "            commands = np.concatenate(([1.0],commands))\n",
        "        else:\n",
        "            commands = np.concatenate(([0.0],commands))\n",
        "        if commands[1] == -1.0:           #append 0/1 depending on turning key value -> defines input for left key\n",
        "            commands =  np.concatenate(([1.0],commands))\n",
        "        else:\n",
        "            commands = np.concatenate(([0.0],commands))\n",
        "        commands = np.delete(commands, 2)\n",
        "        image = image.astype('float')\n",
        "        input_data = self.label_file.iloc[idx, 0:8]\n",
        "        input_data = np.asarray(input_data)\n",
        "        commands = commands.astype('float').reshape(-1)\n",
        "        input_data = input_data.astype('float').reshape(-1)\n",
        "\n",
        "\n",
        "        if self.transforms: \n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        commands = torch.from_numpy(commands)\n",
        "        input_data = torch.from_numpy(input_data)\n",
        "        sample = {'image': image, 'input_data' : input_data,'commands': commands}\n",
        "        return sample\n",
        "\n",
        "class ToTensor(object):\n",
        "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "\n",
        "    def __call__(self, image):\n",
        "\n",
        "        # swap color axis because\n",
        "        # numpy image: H x W x C\n",
        "        # torch image: C X H X W\n",
        "        image = image.transpose((2, 0, 1))\n",
        "        image = torch.from_numpy(image)\n",
        "        return image\n",
        "\n",
        "# instantiate conversion class\n",
        "convert_data = ToTensor()       #initialize convert_data class which is used to transpose image in steeringcommands class\n",
        "\n",
        "#create first dataset containing all images \n",
        "transformed_dataset = SteeringCommands(csv_file=csv_path, root_dir=root_dir, transform=convert_data)\n",
        "#transformed dataset receives csf_file path and image directory path as input, as well as the transform operation defined in the ToTensor() class, which is called for each getitem call\n",
        "\n",
        "\n",
        " \n",
        "    \n",
        "#ONLY FOR DEBUGGING PURPOSES:\n",
        "\n",
        "# number of subprocesses to use for data loading\n",
        "num_workers = 0\n",
        "\n",
        "# samples per batch to load\n",
        "batch_size = 4\n",
        "\n",
        "\"\"\"\n",
        "dataloader = DataLoader(transformed_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "\n",
        "for i_batch, sample_batched in enumerate(dataloader):\n",
        "    #print(sample_batched['commands'])\n",
        "    pass\n",
        "\"\"\"\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "all libraries are imported successfully...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ndataloader = DataLoader(transformed_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\\n\\nfor i_batch, sample_batched in enumerate(dataloader):\\n    #print(sample_batched['commands'])\\n    pass\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d35oLj1AUuRW"
      },
      "source": [
        "This Cell contains the training function and will run for some time.\n",
        "The Hyperparameters in Line 8 to 13 need to be adapted.\n",
        "\n",
        "\n",
        "To change the optimizer to SGD, go to line 71 and replace \n",
        "optimizer = optim.Adam(DenseNet.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
        "with\n",
        "optimizer = optim.SGD(DenseNet.parameters(), lr=0.01, momentum=0.9).\n",
        "Research Values for learning rate and momentum!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weMcum4wlgbv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "342ae220-8b34-46db-eb46-879fd429cba3"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#----------- Parameters to be adapted! ------------\n",
        "validation = False   #specify whether validation shall be done\n",
        "batch_size = 32  #hyper parameter - amount of images in one batch - will be passed to the NN at once\n",
        "nr_epochs = 100   #hyper parameter - determnies how many times the whole training set gets looped through the Neural Network\n",
        "calculate_mean_and_std = False    #decide whether mean and std shall be calculated for whole dataset - takes some time on colab\n",
        "load_pretrained_model = False     #decide whether you want to load parameters for the Model that were trained previously\n",
        "path_to_pretrained_data = \"/content/trained_desnenet.pth\" #only relevant if \"load_pretrained_model\" set to true, path to parameters of model\n",
        "#--------------------------------------------------\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")     #check if gpu is available for training\n",
        "\n",
        "print(\"Creating Model and Loading Trainingdata\")\n",
        "DenseNet = DenseNet(in_channels=2, layer_size=[6,6,8,7], growth_rate=12, additional_neurons = 8).to(device=device)  #initialize DenseNet - Adapt Parameters!!!\n",
        "\n",
        "if(load_pretrained_model == True):\n",
        "  DenseNet.load_state_dict(torch.load(path_to_pretrained_data)['model_state_dict'])    #uncomment, if you want to continue to train a previously saved progress\n",
        "\n",
        "DenseNet = DenseNet.float()     #convert parameters of network to float\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Using GPU for training\")\n",
        "    DenseNet = DenseNet.cuda()  #load densenet to gpu if available\n",
        "\n",
        "DenseNet.train()    #activate train mode for Densenet - Batchnorm activated & allows to pass batches\n",
        "\n",
        "\n",
        "mean_r = 1.1384    #initialize mean value for red input pixel normalization\n",
        "mean_g = 194.1198    #initialize mean value for green input pixel normalization\n",
        "std_r = 16.9998     #initialize standard deviation value for red input pixel normalization\n",
        "std_g = 108.7109     #initialize standard deviation value for green input pixel normalization\n",
        "\n",
        "loader = DataLoader(transformed_dataset, batch_size=len(transformed_dataset), num_workers=0)    #create a dataset which contains all elements of dataLoading.dataset, in order to calculate mean and std     \n",
        "\n",
        "if calculate_mean_and_std == True:\n",
        "  print(\"Calculating Mean & Std for Green & Red Pixles\")\n",
        "  for i_batch, sample_batched in enumerate(loader):   #calculate meand and std of the whole training set but individually for each channel and save values in variables\n",
        "      mean_r = sample_batched['image'][:,0,:,:].mean()\n",
        "      std_r = sample_batched['image'][:,0,:,:].std()\n",
        "      mean_g = sample_batched['image'][:,1,:,:].mean()\n",
        "      std_g = sample_batched['image'][:,1,:,:].std()\n",
        "\n",
        "print(\"Mean Value red: \", mean_r,\", Mean Value green: \", mean_g)\n",
        "print(\"Standard Deviation red: \", std_r, \", Standard Deviation green: \", std_g)  #!make sure to use these values during validation / test!\n",
        "\n",
        "transform = transforms.Compose(     #create transform operation which substracts mean for each image tensor and divides by std and also contains normal transpose trainformation for image\n",
        "    [convert_data,\n",
        "     transforms.Normalize(mean=[mean_r, mean_g], std=[std_r, std_g])])\n",
        "\n",
        "normalized_data = SteeringCommands(csv_file=csv_path, root_dir=root_dir, transform=transform)    #create new normalized training set\n",
        "\n",
        "normalized_loader = DataLoader(normalized_data, batch_size=batch_size, shuffle=True, num_workers=0)    #load normalized training set - set hyperparameter batch_size\n",
        "\n",
        "\"\"\" Only for debugging purposes\n",
        "for i_batch, sample_batched in enumerate(normalized_loader):\n",
        "    print(i_batch, sample_batched['image'].size(), sample_batched['input_data'].size(),\n",
        "          sample_batched['commands'].size())\n",
        "    print(sample_batched['image'][0])\n",
        "    print(\"Tpye Image: \",type(sample_batched['image'][0]))\n",
        "    print(\"Type Commands:, \", type(sample_batched['commands'][0]))\n",
        "\"\"\"\n",
        "\n",
        "criterion = nn.BCELoss()    #defines loss function - Loss function used here is binary cross entropy loss (CEL for sigmoid)\n",
        "if torch.cuda.is_available():\n",
        "    criterion = nn.BCELoss().cuda()\n",
        "optimizer = optimizer = optim.SGD(DenseNet.parameters(), lr=0.01, momentum=0.9)#optim.Adam(DenseNet.parameters(), lr=0.001, betas=(0.9, 0.999)) #define optimizer - set hyper parameters lr and betas\n",
        "if(load_pretrained_model == True):\n",
        "  optimizer.load_state_dict(torch.load(path_to_pretrained_data)['optimizer_state_dict'])\n",
        "\n",
        "if(True):\n",
        "    print(\"Starting Training\")\n",
        "    \n",
        "    for epoch in range(nr_epochs):      #loop which trainis the NN with the normalized dataset \"nr_epochs\" times. - set hyperparameter nr_epochs \n",
        "        \n",
        "        running_loss = 0    #variable to calculate runnning loss (only for output in console)\n",
        "        \n",
        "        for i, data in enumerate(normalized_loader):        #loop which goes through whole normalized dataset once\n",
        "            if torch.cuda.is_available():\n",
        "                images = data['image'].cuda()                         #split up data dictionary in images, commands(steering, acceleration,brake) and inputs(speed, abs, gyroscope, steering)\n",
        "                commands = data['commands'].cuda()\n",
        "                inputs = data['input_data'].cuda()\n",
        "            if not torch.cuda.is_available():           #transfer tensors to gpu if available \n",
        "                images = data['image']\n",
        "                commands = data['commands']\n",
        "                inputs = data['input_data']\n",
        "            \n",
        "            optimizer.zero_grad()       #resets all gradients to zero \n",
        "            \n",
        "            outputs = DenseNet(images.float(), inputs.float())  #calculate output of one batch, input tensors have to consist of float numbers\n",
        "            loss = criterion(outputs.float(), commands.float())     #calculate loss, therefore convert function inputs (output of NN and labels) to float\n",
        "            loss.backward()     #calculate gradient for each parameter based on loss -> dloss/dx\n",
        "            \n",
        "            optimizer.step()    #adapts values of NN\n",
        "            \n",
        "            running_loss += loss.item()     #add loss of this batch to running loss in order to calculate mean loss later on\n",
        "            if i % 50 == 49:    # print every 50 mini-batches\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / 50))   #print running loss on screen\n",
        "                running_loss = 0.0  #reset running loss\n",
        "                \n",
        "        print(\"Epoch \", epoch + 1, \" finished\")\n",
        "        if((epoch+1) % 5 == 0):\n",
        "          print(\"Intermediate result saved.\")   \n",
        "          PATH = './trained_densenetepoch'+str(int(epoch) + 1)+'.pth' \n",
        "          torch.save({          #save current state dict of model\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': DenseNet.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, PATH)\n",
        "    \n",
        "    print('Finished Training')\n",
        "\n",
        "\n",
        "normalized_loader_validation = DataLoader(normalized_data, batch_size=1, shuffle=True, num_workers=0)\n",
        "\n",
        "\n",
        "if(validation == True):\n",
        "    print(\"Starting Validation\")\n",
        "    \n",
        "    running_loss = 0\n",
        "    \n",
        "    DenseNet.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(normalized_loader_validation):        \n",
        "            images = data['image']                          #split up data dictionary in images, commands(steering, acceleration,brake) and inputs(speed, abs, gyroscope, steering)\n",
        "            commands = data['commands']\n",
        "            inputs = data['input_data']\n",
        "            if torch.cuda.is_available():           #transfer tensors to gpu if available \n",
        "                commands = commands.cuda()\n",
        "                inputs = inputs.cuda()\n",
        "                images = images.cuda()\n",
        "            outputs = DenseNet(images.float(), inputs.float())\n",
        "            commands = torch.squeeze(commands, 0)   #remove unnessecary dimension form commands tensor size:[1,4] -> size:[4]\n",
        "            loss = criterion(outputs.float(), commands.float())   \n",
        "            running_loss += loss.item()                       \n",
        "            if i % 100 == 99:    # print every 50 mini-batches\n",
        "                print('loss: %.3f' %\n",
        "                      (running_loss / 100))\n",
        "                print(\"Sample Tensor Output:\", outputs)\n",
        "                print(\"Sample Desired Output:\", commands)\n",
        "                running_loss = 0.0  \n",
        "            \n",
        "    print(\"Finished Validation\")\n",
        "\n",
        "\n",
        "#make sure to download the file after training is finished\n",
        "print(\"Parameters Saved. Please make sure to download the file\")\n",
        "PATH = './trained_densenetepoch'+str(int(epoch) + 1)+'.pth'\n",
        "torch.save({          #save current state dict of model\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': DenseNet.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating Model and Loading Trainingdata\n",
            "Using GPU for training\n",
            "Mean Value red:  1.1384 , Mean Value green:  194.1198\n",
            "Standard Deviation red:  16.9998 , Standard Deviation green:  108.7109\n",
            "Starting Training\n",
            "[1,    50] loss: 0.344\n",
            "[1,   100] loss: 0.307\n",
            "[1,   150] loss: 0.293\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}